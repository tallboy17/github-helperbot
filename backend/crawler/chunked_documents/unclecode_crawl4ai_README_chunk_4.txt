Repository: unclecode/crawl4ai
Language: Python
Stars: 45928
Forks: 4368
-----
<details>
<summary>ğŸ“ <strong>Markdown Generation</strong></summary>  
- ğŸ§¹ **Clean Markdown**: Generates clean, structured Markdown with accurate formatting.
- ğŸ¯ **Fit Markdown**: Heuristic-based filtering to remove noise and irrelevant parts for AI-friendly processing.
- ğŸ”— **Citations and References**: Converts page links into a numbered reference list with clean citations.
- ğŸ› ï¸ **Custom Strategies**: Users can create their own Markdown generation strategies tailored to specific needs.
- ğŸ“š **BM25 Algorithm**: Employs BM25-based filtering for extracting core information and removing irrelevant content.
</details>  
<details>
<summary>ğŸ“Š <strong>Structured Data Extraction</strong></summary>  
- ğŸ¤– **LLM-Driven Extraction**: Supports all LLMs (open-source and proprietary) for structured data extraction.
- ğŸ§± **Chunking Strategies**: Implements chunking (topic-based, regex, sentence-level) for targeted content processing.
- ğŸŒŒ **Cosine Similarity**: Find relevant content chunks based on user queries for semantic extraction.
- ğŸ” **CSS-Based Extraction**: Fast schema-based data extraction using XPath and CSS selectors.
- ğŸ”§ **Schema Definition**: Define custom schemas for extracting structured JSON from repetitive patterns.  
</details>  
<details>
<summary>ğŸŒ <strong>Browser Integration</strong></summary>  
- ğŸ–¥ï¸ **Managed Browser**: Use user-owned browsers with full control, avoiding bot detection.
- ğŸ”„ **Remote Browser Control**: Connect to Chrome Developer Tools Protocol for remote, large-scale data extraction.
- ğŸ‘¤ **Browser Profiler**: Create and manage persistent profiles with saved authentication states, cookies, and settings.
- ğŸ”’ **Session Management**: Preserve browser states and reuse them for multi-step crawling.
- ğŸ§© **Proxy Support**: Seamlessly connect to proxies with authentication for secure access.
- âš™ï¸ **Full Browser Control**: Modify headers, cookies, user agents, and more for tailored crawling setups.
- ğŸŒ **Multi-Browser Support**: Compatible with Chromium, Firefox, and WebKit.
- ğŸ“ **Dynamic Viewport Adjustment**: Automatically adjusts the browser viewport to match page content, ensuring complete rendering and capturing of all elements.  
</details>  
<details>
<summary>ğŸ” <strong>Crawling & Scraping</strong></summary>  
- ğŸ–¼ï¸ **Media Support**: Extract images, audio, videos, and responsive image formats like `srcset` and `picture`.
- ğŸš€ **Dynamic Crawling**: Execute JS and wait for async or sync for dynamic content extraction.
- ğŸ“¸ **Screenshots**: Capture page screenshots during crawling for debugging or analysis.
- ğŸ“‚ **Raw Data Crawling**: Directly process raw HTML (`raw:`) or local files (`file://`).
- ğŸ”— **Comprehensive Link Extraction**: Extracts internal, external links, and embedded iframe content.
- ğŸ› ï¸ **Customizable Hooks**: Define hooks at every step to customize crawling behavior.
- ğŸ’¾ **Caching**: Cache data for improved speed and to avoid redundant fetches.
- ğŸ“„ **Metadata Extraction**: Retrieve structured metadata from web pages.
- ğŸ“¡ **IFrame Content Extraction**: Seamless extraction from embedded iframe content.
- ğŸ•µï¸ **Lazy Load Handling**: Waits for images to fully load, ensuring no content is missed due to lazy loading.
- ğŸ”„ **Full-Page Scanning**: Simulates scrolling to load and capture all dynamic content, perfect for infinite scroll pages.  
</details>  
<details>
<summary>ğŸš€ <strong>Deployment</strong></summary>  
- ğŸ³ **Dockerized Setup**: Optimized Docker image with FastAPI server for easy deployment.
- ğŸ”‘ **Secure Authentication**: Built-in JWT token authentication for API security.
- ğŸ”„ **API Gateway**: One-click deployment with secure token authentication for API-based workflows.
- ğŸŒ **Scalable Architecture**: Designed for mass-scale production and optimized server performance.
- â˜ï¸ **Cloud Deployment**: Ready-to-deploy configurations for major cloud platforms.  
</details>  
<details>
<summary>ğŸ¯ <strong>Additional Features</strong></summary>  
- ğŸ•¶ï¸ **Stealth Mode**: Avoid bot detection by mimicking real users.
- ğŸ·ï¸ **Tag-Based Content Extraction**: Refine crawling based on custom tags, headers, or metadata.
- ğŸ”— **Link Analysis**: Extract and analyze all links for detailed data exploration.
- ğŸ›¡ï¸ **Error Handling**: Robust error management for seamless execution.
- ğŸ” **CORS & Static Serving**: Supports filesystem-based caching and cross-origin requests.
- ğŸ“– **Clear Documentation**: Simplified and updated guides for onboarding and advanced usage.
- ğŸ™Œ **Community Recognition**: Acknowledges contributors and pull requests for transparency.  
</details>