Repository: google-research/bert
Language: Python
Stars: 39243
Forks: 9676
-----
So far we have not attempted to train anything larger than `BERT-Large`. It is
possible that we will release larger models if we are able to obtain significant
improvements.